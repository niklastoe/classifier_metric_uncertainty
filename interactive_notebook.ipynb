{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your Classifier's Performance - Don't Neglect Uncertainty!\n",
    "\n",
    "Metrics such as sensitivity, specificity etc. are needed to evaluate how well binary classifiers work. \n",
    "These are calculated from the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) which lists true positive (TP), true negative (TN), false positive (FP) and false negative (FN) predictions.\n",
    "\n",
    "If the sample size is small, these metrics are highly uncertain as we have shown in [our manuscript](https://arxiv.org/abs/2006.11105). If you want to determine the uncertainty of your classifier's metric, use this tool. All settings are identical to the protocol in our paper.\n",
    "\n",
    "# Options\n",
    "\n",
    "Currently, you can do the following here:\n",
    "\n",
    "1. Calculate and visualize uncertainty of a metric for a single classifier\n",
    "2. Compare the posterior distributions of the same metric for two classifiers\n",
    "3. Estimate the sample size necessary to reduce metric uncertainty to an acceptable level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Metric uncertainty for 1 classifier\n",
    "\n",
    "All you have to do (boxes on the left side, from top to bottom):\n",
    "\n",
    "1. Enter your confusion matrix\n",
    "2. Select your metric of interest (nomenclature follows [Wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix))\n",
    "3. Select boundaries to integrate $\\int_{low}^{high} p(\\mathrm{metric} | D) d\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font', **{'size': 36})\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets\n",
    "\n",
    "\n",
    "from __init__ import ConfusionMatrixAnalyser, NewPrevalence, BetaBinomialDist, triplebeta_priors\n",
    "from classifier_comparison import classifier_outperformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyser = ConfusionMatrixAnalyser(pd.Series([5, 5, 5, 5], index=['TP', 'FN', 'TN', 'FP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_cma(TP, TN, FN, FP):\n",
    "    cm = pd.Series({'TP': int(TP),\n",
    "                    'TN': int(TN),\n",
    "                    'FN': int(FN),\n",
    "                    'FP': int(FP)})\n",
    "    \n",
    "    analyser = ConfusionMatrixAnalyser(cm, triplebeta_priors['Bayes-Laplace'])\n",
    "    return analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigger = 'Please select'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def catch_select(metric):\n",
    "    if metric == trigger:\n",
    "        return 'BM'\n",
    "    else:\n",
    "        return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metric(TP, TN, FN, FP, \n",
    "                metric='BM', point_estimate=True, theta=True, posterior_prediction=False):\n",
    "\n",
    "    analyser = generate_cma(TP, TN, FN, FP)\n",
    "    \n",
    "    metric = catch_select(metric)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.rc('font', size=22) \n",
    "    analyser.plot_metric(metric, \n",
    "                         theta, \n",
    "                         posterior_prediction,\n",
    "                         point_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integrate(TP, TN, FN, FP, \n",
    "              metric='BM', low_bound=-1., high_bound=1.):\n",
    "    \n",
    "    analyser = generate_cma(TP, TN, FN, FP)\n",
    "\n",
    "    metric = catch_select(metric)\n",
    "\n",
    "    integral = analyser.integrate_metric(metric, \n",
    "                                  low_bound, \n",
    "                                  high_bound)\n",
    "    \n",
    "    print('Probability that %s < %s < %s: %2d' % (str(low_bound), metric, str(high_bound), np.round(integral*100)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_hpd(TP, TN, FN, FP, \n",
    "              metric='BM'):\n",
    "    \n",
    "    analyser = generate_cma(TP, TN, FN, FP)\n",
    "    \n",
    "    metric = catch_select(metric)\n",
    "    \n",
    "    hpd = analyser.calc_hpd(analyser.theta_metrics[metric])\n",
    "    \n",
    "    print('95% credible interval:' +  '%3.2f to %3.2f' % (np.round(hpd[0], decimals=2), np.round(hpd[1], decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metric_definition(metric):\n",
    "    metric = catch_select(metric)\n",
    "    \n",
    "    print(metric + ' = ')\n",
    "    print(analyser.metrics['symbolic'][metric])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate necessary inputs\n",
    "tp, tn, fn, fp = [ipywidgets.Text('5') for i in range(4)]\n",
    "\n",
    "low_bound = ipywidgets.FloatSlider(value=0., min=-1., max=1., step=0.1)\n",
    "high_bound = ipywidgets.FloatSlider(value=1., min=-1., max=1., step=0.1)\n",
    "\n",
    "# add fake entry or not?\n",
    "metric_dropdown = ipywidgets.Dropdown(options=[trigger] + list(analyser.theta_metrics.columns), value=trigger)\n",
    "metric_dropdown = ipywidgets.ToggleButtons(options=list(analyser.theta_metrics.columns), value='BM')\n",
    "\n",
    "point_estimate = ipywidgets.Checkbox(value=True, description='point estimate')\n",
    "theta = ipywidgets.Checkbox(value=True, description='Bayes')\n",
    "empirical = ipywidgets.Checkbox(description='empirical')\n",
    "\n",
    "plt.figure()\n",
    "plot = ipywidgets.interactive(plot_metric, \n",
    "                              TP=tp,TN=tn,FN=fn,FP=fp,\n",
    "                              metric=metric_dropdown, \n",
    "                              point_estimate=point_estimate, theta=theta, posterior_prediction=empirical)\n",
    "\n",
    "integration = ipywidgets.interactive(integrate, \n",
    "                                     TP=tp,TN=tn,FN=fn,FP=fp,\n",
    "                                     metric=metric_dropdown, low_bound=low_bound, high_bound=high_bound)\n",
    "hpd = ipywidgets.interactive(print_hpd, \n",
    "                             TP=tp,TN=tn,FN=fn,FP=fp,\n",
    "                             metric=metric_dropdown)\n",
    "metric = ipywidgets.interactive(print_metric_definition,\n",
    "                               metric=metric_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout_settings = {'display': 'flex',\n",
    "                   'flex_flow': 'column',\n",
    "                   'align_items': 'stretch',\n",
    "                   'border': 'solid'}\n",
    "\n",
    "input_layout = ipywidgets.Layout(width='35%', **layout_settings)\n",
    "\n",
    "output_layout = ipywidgets.Layout(width='65%', **layout_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "box_layout_full = ipywidgets.Layout(display='flex',\n",
    "                    flex_flow='column',\n",
    "                    align_items='stretch',\n",
    "                    border='dashed',\n",
    "                    width='100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_box = ipywidgets.VBox(children=plot.children[:4], layout=box_layout_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotting_box = ipywidgets.VBox(children=plot.children[4:5] +  metric.children[-1:] + plot.children[5:8], layout=box_layout_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "integration_box = ipywidgets.VBox(children=integration.children[5:-1], layout=box_layout_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_box = ipywidgets.VBox(children=[cm_box, plotting_box, integration_box], layout=input_layout)\n",
    "output_box = ipywidgets.VBox(children=[plot.children[-1], hpd.children[-1], integration.children[-1]], layout=output_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullbox = ipywidgets.HBox(children=[input_box, output_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17550b6420f94414b92fd99895e8ef0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fullbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare posterior distributions for two classifiers\n",
    "\n",
    "We will use the same confusion matrix from above for classifier A, you only need to input the one for classifier B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp2, tn2, fn2, fp2 = [ipywidgets.Text('8'), ipywidgets.Text('4'), ipywidgets.Text('2'), ipywidgets.Text('6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_classifier_comparison(TP, TN, FN, FP,\n",
    "                               TP2, TN2, FN2, FP2,\n",
    "                               metric='BM', point_estimate=True, theta=True, posterior_prediction=False):\n",
    "    \n",
    "    analyser1 = generate_cma(TP, TN, FN, FP)\n",
    "    analyser2 = generate_cma(TP2, TN2, FN2, FP2)\n",
    "\n",
    "    metric = catch_select(metric)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.rc('font', size=22) \n",
    "    \n",
    "    analyser1.plot_metric(metric, \n",
    "                          theta, \n",
    "                          posterior_prediction,\n",
    "                          point_estimate)\n",
    "    analyser2.plot_metric(metric, \n",
    "                          theta, \n",
    "                          posterior_prediction,\n",
    "                          point_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_outperformance_probability(TP, TN, FN, FP,\n",
    "                               TP2, TN2, FN2, FP2,\n",
    "                               metric='BM'):\n",
    "    \n",
    "    analyser1 = generate_cma(TP, TN, FN, FP)\n",
    "    analyser2 = generate_cma(TP2, TN2, FN2, FP2)\n",
    "\n",
    "    metric = catch_select(metric)\n",
    "    \n",
    "    outperformance = (analyser1.theta_metrics[metric] >  analyser2.theta_metrics[metric]).sum()\n",
    "    outperformance /= float(len(analyser1.theta_metrics[metric]))\n",
    "\n",
    "    print('Chance that classifier 1 is better than classifier 2 w.r.t. %s: %d' % (metric, np.round(outperformance*100)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_comparison = ipywidgets.interactive(plot_classifier_comparison, \n",
    "                                         TP=tp,TN=tn,FN=fn,FP=fp,\n",
    "                                         TP2=tp2,TN2=tn2,FN2=fn2,FP2=fp2,\n",
    "                                         metric=metric_dropdown,\n",
    "                                         point_estimate=point_estimate, theta=theta, posterior_prediction=empirical)\n",
    "\n",
    "outperformance_comparison = ipywidgets.interactive(calc_outperformance_probability, \n",
    "                              TP=tp,TN=tn,FN=fn,FP=fp,\n",
    "                              TP2=tp2,TN2=tn2,FN2=fn2,FP2=fp2,\n",
    "                              metric=metric_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm2_box = ipywidgets.VBox(children=plot_comparison.children[4:8], layout=box_layout_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison_input_box = ipywidgets.VBox(children=[cm_box, cm2_box, plotting_box], layout=input_layout)\n",
    "comparison_output_box = ipywidgets.VBox(children=[plot_comparison.children[-1], outperformance_comparison.children[-1]], layout=output_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison_fullbox = ipywidgets.HBox(children=[comparison_input_box, comparison_output_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabb0d95a4bc49c1860f9b672eafe9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_fullbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample size estimation\n",
    "\n",
    "In our manuscript, we have shown that metric uncertainty (MU) can be approximated for $N$>20 by \n",
    "\n",
    "$$\n",
    "MU = \\frac{2}{\\sqrt{N}}\n",
    "$$\n",
    "\n",
    "where $N$ is the sample size. $N$ can mean different things depending on the metric:\n",
    "\n",
    "| metric | interpretation |\n",
    "|-----|----------------|\n",
    "|PREVALENCE| all samples | \n",
    "| ACC | all samples    |\n",
    "| TPR | real positives |\n",
    "| TNR | real negatives |\n",
    "| PPV | predicted positives|\n",
    "| NPV | predicted negatives|\n",
    "\n",
    "Please note that this only serves as a rule of thumb! It will give you a realistic order of magnitude which allows you to determine if a level of uncertainty is achievable. It obviously neglects any previous information that you have about your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb8abf92b7a4b1da49c0328263641b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2634835dd144539a45050513c1c2480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.calc_N>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warning_message = \"This rule of thumb is only reasonable if N>20, MU < 45%!!\"\n",
    "\n",
    "def calc_MU(N):\n",
    "    N = int(N)\n",
    "    MU = 2. / np.sqrt(N)\n",
    "    formatted_string = r'       MU = %2.1e = %3.1f' %  (MU, MU * 100) + '%'\n",
    "    \n",
    "    if N <= 20 or MU >= 0.45:\n",
    "        print(warning_message)\n",
    "    else:\n",
    "        print(formatted_string)\n",
    "\n",
    "ipywidgets.interact(calc_MU, N='100')\n",
    "\n",
    "def calc_N(MU):\n",
    "    MU = float(MU)\n",
    "    N = 4. / MU**2\n",
    "    formatted_string = r'        N = %2.1e = %d' %  (N, np.round(N))\n",
    "    \n",
    "    \n",
    "    if N <= 20 or MU >= 0.45:\n",
    "        print(warning_message)\n",
    "    else:\n",
    "        print(formatted_string)\n",
    "\n",
    "ipywidgets.interact(calc_N, MU='0.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "# Please ignore everything below, it is redundant and only needed to ensure that everything works correctly.\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd60b380e6694805848f38e0511e1e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot\n",
    "integration\n",
    "hpd \n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fffcaef40a497590a0323e9d3491b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_comparison\n",
    "outperformance_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
